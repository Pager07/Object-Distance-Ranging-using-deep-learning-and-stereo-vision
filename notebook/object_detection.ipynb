{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Given an image, this module returns\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN\n",
    " - Generate binary mask(Done)\n",
    " - Generate segmented image(DONE)\n",
    " - Write a function thats returns the following:\n",
    "     - {'class_name':classes[classIDs[detected_object]],\n",
    "        'left':left,\n",
    "        'top':top\n",
    "        'right': right\n",
    "        'bottom':bottom,\n",
    "        'countour': countour\n",
    "       }\n",
    "     - left_segmented_images\n",
    "     - right_segmented_images \n",
    "- Write a function that draws poloygon with distance label and returns image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import argparse\n",
    "import sys\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes\n",
    "classes_file = \"/Users/sandeep/Desktop/MaskRCNNopencv/mscoco_labels.names\"\n",
    "# Load text graph and weight files for the model\n",
    "text_graph = '/Users/sandeep/Desktop/MaskRCNNopencv/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt'\n",
    "model_weights = '/Users/sandeep/Desktop/MaskRCNNopencv/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb'\n",
    "# Load colors\n",
    "colors_file = \"/Users/sandeep/Desktop/MaskRCNNopencv/colors.txt\"\n",
    "classes = None\n",
    "\n",
    "with open(classes_file, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "\n",
    "with open(colors_file, 'rt') as f:\n",
    "    colors_str = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "colors = []\n",
    "for i in range(len(colors_str)):\n",
    "    rgb = colors_str[i].split(' ')\n",
    "    color = np.array([float(rgb[0]), float(rgb[1]), float(rgb[2])])\n",
    "    colors.append(color)\n",
    "\n",
    "\n",
    "# Load network\n",
    "net = cv.dnn.readNetFromTensorflow(model_weights, text_graph)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "# This is a global variable that will store the img that needs to be proccessed\n",
    "frame = None\n",
    "#This will store final segemented images that will be returned \n",
    "segmented_frame = None\n",
    "# detected_obj details\n",
    "detected_obj = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence and mask threshold\n",
    "conf_threshold = 0.9\n",
    "mask_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPred(image, class_name, left, top, right, bottom, colour,z):\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), colour, 3)\n",
    "\n",
    "    # construct label\n",
    "    # construct label\n",
    "    label = f'{class_name}:{round(z,2)}m'\n",
    "\n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv2.rectangle(image, (left, top - round(1.5*labelSize[1])),\n",
    "        (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.putText(image, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_mask_frame(frame, left, top, right, bottom, class_mask):\n",
    "    class_mask = cv.resize(class_mask, (right - left + 1, bottom - top + 1))\n",
    "    filtering_mask = (class_mask > mask_threshold)\n",
    "    roi = frame[top:bottom+1, left:right+1][filtering_mask]\n",
    "    frame[top:bottom+1, left:right+1][filtering_mask] = np.array(([255.0,255.0,255.0])).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each detected object in a frame, extract bounding box and mask\n",
    "def postprocess(boxes, masks):\n",
    "    global frame\n",
    "    global segmented_frame\n",
    "    num_classes = masks.shape[1]\n",
    "    num_detections = boxes.shape[2]\n",
    "\n",
    "    frame_H = frame.shape[0]\n",
    "    frame_W = frame.shape[1]\n",
    "\n",
    "    #Blank black frame, same size as frame. To be used as template of binary mask\n",
    "    mask_frame = np.zeros((frame.shape[0],frame.shape[1],3), np.uint8)\n",
    "    \n",
    "    # a capy of original image\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    for i in range(num_detections):\n",
    "        box = boxes[0, 0, i]\n",
    "        mask = masks[i]\n",
    "        score = box[2]\n",
    "        if score > conf_threshold:\n",
    "            class_id = int(box[1])\n",
    "\n",
    "            # Extract the bounding box\n",
    "            left = int(frame_W * box[3])\n",
    "            top = int(frame_H * box[4])\n",
    "            right = int(frame_W * box[5])\n",
    "            bottom = int(frame_H * box[6])\n",
    "\n",
    "            left = max(0, min(left, frame_W-1))\n",
    "            top = max(0, min(top, frame_H-1))\n",
    "            right = max(0, min(right, frame_W-1))\n",
    "            bottom = max(0, min(bottom, frame_H-1))\n",
    "\n",
    "            # Extract the mask for the object\n",
    "            class_mask = mask[class_id]\n",
    "            class_mask = cv.resize(class_mask, (right - left + 1, bottom - top + 1))\n",
    "            #generate mask \n",
    "            set_mask_frame(mask_frame, left, top, right, bottom, class_mask)\n",
    "            detected_obj[i] = {'class_name': classes[class_id],\n",
    "                              'left':left, 'top':top , 'right':right , 'bottom':bottom,\n",
    "                               'class_mask':class_mask}\n",
    "    \n",
    "    # Uses the binary mask frame and orignial frame copy to produce frame with only object in it \n",
    "#     segmented_framex = cv.subtract(mask_frame,frame_copy)\n",
    "#     segmented_framex = cv.subtract(mask_frame,segmented_framex)\n",
    "    \n",
    "#     white_img = np.zeros(frame.shape, np.uint8)\n",
    "#     white_img[:] = 255.0\n",
    "#     segmented_frame =cv.subtract(white_img,mask_frame)\n",
    "#     segmented_frame = cv.subtract(segmented_frame,mask_frame)\n",
    "\n",
    "#     segmented_frame = cv.add(segmented_frame,segmented_framex)\n",
    "    segmented_frame = mask_frame\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img):\n",
    "    #set the global variable\n",
    "    global frame\n",
    "    frame= img\n",
    "    # create a 4D blob from  a frame\n",
    "    # swapRB: boolean to indicate if we want to swap the first and last channel in 3 channel image.\n",
    "    #       : OpenCV assumes that images are in BGR format by default but if we want to swap this order to RGB,\n",
    "    blob = cv.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "\n",
    "    # set input to the network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run the forward pass computation to get output from the output layers\n",
    "    boxes, masks = net.forward(['detection_out_final', 'detection_masks'])\n",
    "    \n",
    "    postprocess(boxes, masks)\n",
    "    \n",
    "    return segmented_frame, detected_obj\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('/Users/sandeep/Desktop/MaskRCNNopencv/example.png')\n",
    "a,b = process_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('window',a)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_m = b[0]['class_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_m = (c_m > 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = {'a':'b','a':'b' }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
